{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START,END, StateGraph\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import regex as re\n",
    "from resources import cv, jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "llm = ChatCohere(cohere_api_key=key, temperature= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(MessagesState):\n",
    "    cv : str\n",
    "    job_description : str\n",
    "    keywords : str\n",
    "    score : int\n",
    "    suggestions : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = 0\n",
    "max_attempts = 3\n",
    "\n",
    "generater_messages = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \n",
    "    \"\"\" You are an excellent CV generating AI assistant. Given a base CV and the Job description,\n",
    "        your job is to generate a CV that perfectly matches the job description. Especially it should reflect\n",
    "        in the candidate's summary section, skills and expertise section, experience and the type of projects\n",
    "        they have worked on. The CV should contain all the ATS friendly keywords so that it can easily pass the \n",
    "        Application tracking system. Don't alter the template of the base CV. Don't add any additional information\n",
    "        that is not present in the base CV. Write the content that is already present in a different way by\n",
    "        including all the necessary keywords.\n",
    "                  \n",
    "        Some times the user might provide a list of keywords to be used and some suggestions to improve their CV.\n",
    "        Keep that as well into account while generating the CV.\n",
    "        \n",
    "        Your response formate should be : \"cv : [CV]\" \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(\"history\")\n",
    "])\n",
    "\n",
    "generater_human_message = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"human\",\n",
    "    \"\"\" Here's my base CV: {base_cv}.\n",
    "    And this is my job description: {job_description}.\n",
    "\n",
    "    Add these keywords to the CV: {keywords}.\n",
    "    Here are some suggestions: {suggestions}.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    )\n",
    "\n",
    "evaluater_messages = ChatPromptTemplate.from_messages([(\n",
    "    \"system\",\n",
    "    \"\"\" You are an excellent CV evaluating AI assistant. Given a CV and a job description, your\n",
    "        job is to evaluate how well the CV is matching with the job description. You have to check whether the\n",
    "        CV contains all the ATS friendly keywords. You have to provide a score out of 100 based on these\n",
    "        mentioned criterias. Also if you think that the CV needs any improvement you need to provide\n",
    "        area of improvements in not more than 200 words.\n",
    "\n",
    "        Your response formate should be : \n",
    "        \n",
    "        \"score : [score]. \n",
    "        suggestions : [suggestions].\n",
    "        missing keywords : [keywords].\" \"\"\"),\n",
    "\n",
    "        MessagesPlaceholder(\"history\")\n",
    "])\n",
    "\n",
    "evaluater_human_message = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \n",
    "     \"\"\"This is my CV: {cv}. This is my job description: {job_description}.\"\"\")])\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generater(state : state):\n",
    "    global generater_human_message,generater_messages\n",
    "    print(\"*********************INSIDE GENERATER*********************\")\n",
    "    generater_human_prompt = generater_human_message.invoke({\"base_cv\": state[\"cv\"], \"job_description\": state[\"job_description\"], \"keywords\": state[\"keywords\"], \"suggestions\": state[\"suggestions\"]})\n",
    "    state[\"messages\"] = generater_human_prompt.messages\n",
    "    gprompt = generater_messages.invoke({\"history\": state[\"messages\"]})\n",
    "    print(gprompt)\n",
    "    response = llm.invoke(gprompt)\n",
    "    pattern = r\"cv : ((.|\\n)+)\"\n",
    "    print(response.content[:500])\n",
    "    match = re.search(pattern, response.content.lower())\n",
    "    if match:\n",
    "        print(\"================================================MATCHED!!!!!!!!!!!===============================\")\n",
    "        state[\"cv\"] = match.group(1)\n",
    "    return {\"cv\" : state[\"cv\"]}\n",
    "\n",
    "def evaluater(state : state):\n",
    "    global evaluater_human_message, evaluater_messages\n",
    "    print(\"*********************INSIDE EVALUATOR*********************\")\n",
    "    print(\"cv : \", state[\"cv\"][:500])\n",
    "    evaluater_human_prompt = evaluater_human_message.invoke({\"cv\": state[\"cv\"], \"job_description\": state[\"job_description\"]})\n",
    "    state[\"messages\"] = evaluater_human_prompt.messages\n",
    "    eprompt = evaluater_messages.invoke({\"history\": state[\"messages\"]})\n",
    "    response = llm.invoke(eprompt)\n",
    "    pattern = r\"score.*?(\\d+)\"\n",
    "    match = re.search(pattern, response.content.lower())\n",
    "    if match:\n",
    "        state[\"score\"] = int(match.group(1))\n",
    "    pattern = r\"(?<=suggestions:\\n)((?:- .*\\n?)+)\"\n",
    "    match = re.search(pattern, response.content.lower())\n",
    "    if match:\n",
    "        state[\"suggestions\"] = match.group(1)\n",
    "    pattern = r\"(?<=missing keywords:\\n)((?:- .*\\n?)+)\"\n",
    "    match = re.search(pattern, response.content.lower())\n",
    "    if match:\n",
    "        state[\"keywords\"] = match.group(1)\n",
    "\n",
    "    return {\"messages\" : response, \"score\" : int(state[\"score\"]), \"keywords\" : state[\"keywords\"], \"suggestions\" : state[\"suggestions\"]}\n",
    "\n",
    "def decide_node(state: state):\n",
    "    global attempts, max_attempts\n",
    "    attempts += 1\n",
    "    print(\"================================ATTEMPT : \", str(attempts), \"================================\")\n",
    "    score = state[\"score\"]\n",
    "    print(\"*********************INSIDE DECIDE NODE*********************\")\n",
    "    print(\"Score : \", score)\n",
    "    if score >= 90 or attempts == max_attempts:\n",
    "        print(state[\"cv\"])\n",
    "        return END\n",
    "    else:\n",
    "        return \"generater\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(state)\n",
    "\n",
    "graph.add_node(\"generater\", generater)\n",
    "graph.add_node(\"evaluater\", evaluater)\n",
    "graph.add_edge(START, \"generater\")\n",
    "graph.add_edge(\"generater\", \"evaluater\")\n",
    "graph.add_conditional_edges(\"evaluater\", decide_node)\n",
    "\n",
    "compiled_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_cv = cv\n",
    "user_input_jd = jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIVYAPRAKASH RATHINASABAPATHY – DATA SCIENTIST\n",
      "    rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "London, UK.\n",
      "Passionate Data Scientist with hands-on experience in developing and implementing machine learning models and AI-driven solutions to address real-world challenges. Proficient in leveraging Python for data manipulation and analysis of complex datasets, with a focus on unstructured data, including text, images, and videos. Demonstrated expertise in applying statistical and machine learning techniques to derive actionable insights, communicate technical solutions to non-technical stakeholders, and contribute to data-driven regulatory practices. Seeking to apply my skills to help the ASA effectively monitor online advertising compliance and enhance consumer protection. Portfolio Link.\n",
      "\n",
      "EDUCATION\t\n",
      "Data Science, M.Sc., – Kingston University, U.K.\t\t\t                                                                               Jan 2023 – Jan 2024\n",
      "Electronics and Communication Engineering, B.Tech., – Amrita School of Engineering, India\t\t                             Jul 2017 – May 2021\n",
      "\n",
      "SKILLS AND EXPERTISE\n",
      "\t\n",
      "\tMachine Learning & Statistical Analysis: Proficient in developing, training, and deploying machine learning models in Python, applying various statistical and machine learning techniques, including LLM-based tools, to extract insights from unstructured data.\n",
      "\tData Manipulation & Analysis: Extensive experience in data cleaning, transformation, and validation processes using Python and SQL, ensuring high-quality datasets for analysis.\n",
      "\tUnstructured Data Processing: Skilled in analysing diverse data formats, including text, images, and videos, to identify patterns and inform regulatory priorities in online advertising.\n",
      "\tCommunication & Stakeholder Engagement: Proven ability to convey complex technical solutions to non-technical stakeholders, translating regulatory challenges into actionable data science projects.\n",
      "\tEnd-to-End Project Management: Strong track record of taking ownership of data science projects, from conception through deployment, ensuring alignment with stakeholder needs and regulatory objectives.\n",
      "\n",
      "WORK EXPERIENCE\t\n",
      "\n",
      "AI Engineer Intern – Navi Promotions, Remote. \t\t\t                                                                                   Oct 2024 – Present\n",
      "\tDesigned and developed prototypes for AI solutions in alignment with client specifications, effectively translating complex requirements into functional models that enhance user experience and meet business objectives.\n",
      "\tFine-tuned advanced Hugging Face models for text and speech processing, employing techniques such as hyperparameter tuning and data augmentation to significantly improve model accuracy and response time.\n",
      "\tEngineered and implemented vector databases to support knowledge base applications, facilitating efficient data retrieval and improving the performance of AI-driven systems.\n",
      "\tWorked closely with cross-functional teams, including data scientists and software engineers, to ensure seamless integration of AI solutions and alignment with overall project goals.\n",
      "\tAuthored comprehensive documentation outlining the development processes, model specifications, and database architecture, ensuring clarity and facilitating knowledge transfer within the team.\n",
      "\tEngaged in ongoing evaluation of AI models and databases, identifying areas for improvement and implementing iterative enhancements to maintain cutting-edge performance.\n",
      "\n",
      "Junior Machine Learning Engineer Volunteer – Omdena, Remote. \t\t\t                                               Apr 2024 – Jun 2024\n",
      "\tCollaborated with senior data scientists and clients to identify and define project objectives, gathering requirements and collecting relevant data to effectively address specific business challenges.\n",
      "\tConducted thorough data validation using standardized protocols to ensure accuracy and integrity, laying a solid foundation for subsequent analysis.\n",
      "\tPerformed exploratory data analysis (EDA), including data cleaning, visualization, and documentation, to uncover insights and support informed decision-making.\n",
      "\tActively participated in workshops and training sessions, providing guidance and support to colleagues who required assistance in unfamiliar tasks, fostering a collaborative and inclusive team environment.\n",
      "\tDeveloped comprehensive reports and visualizations to clearly communicate findings to stakeholders, facilitating a better understanding of data-driven insights.\n",
      "\tEngaged in continuous learning and skill development, staying updated with industry best practices to enhance analytical capabilities and contribute effectively to team projects.\n",
      "\n",
      "Salesforce Programmer Analyst trainee – Cognizant Technology Solutions, India.\t\t\t                            Aug 2021 – Nov 2022\n",
      "\tDeveloped and implemented optimizations using Apex code and Lightning components, according to business objectives.\n",
      "\tIntegrated Salesforce with external systems using RESTful and SOAP-based APIs, automating cloud data exchange and improving efficiency.\n",
      "\tDemonstrated strong collaborative skills by collaborating closely with cross-functional teams to understand their requirements and provide effective solutions within the Salesforce ecosystem.\n",
      "\tStayed updated on the latest Salesforce platform features, tools, and technologies, continuously enhancing skills and knowledge to drive innovation and deliver value-added solutions.\n",
      "\n",
      "PROJECT EXPERIENCE\t\n",
      "\n",
      "Supply Chain Analysis Dashboard \t\t\t\t\t\t\t\t\t\t     Dashboard Link\n",
      "\tDeveloped an end-to-end Power BI dashboard for supply chain analysis, helping stakeholders track performance and customer satisfaction.\n",
      "\tUsed Power Query for data cleaning and DAX for advanced calculations, enabling the visualization of key metrics such as OT %, IF %, and OTIF %. Provided a comprehensive analysis that allowed stakeholders to make informed decisions, driving improvements in operational performance.\n",
      "\n",
      "Doctor’s appointment managing Chatbot\t\t\t\t\t\t\t\t\t\t         Link \n",
      "\tDesigned and built an interactive chatbot system for managing doctor appointments, using Google’s Gemini Large Language Model for NLP tasks such as intent and entity recognition.\n",
      "\tImplemented MySQL for database management and used Streamlit for the front-end interface. The chatbot automated tasks like appointment booking, editing, and cancellations, improving operational efficiency and user experience. \n",
      "\n",
      "Predictive Modelling for T20 Cricket:\t\t\t\t\t\t\t\t\t\t                          Link\n",
      "\tCreated a machine learning model for real-time prediction of T20 cricket first innings totals using Python.\n",
      "\tConducted extensive feature engineering and developed a Decision Tree Regression model, achieving RMSE of 6.15 and MAE of 3.07, providing accurate and timely predictions for in-game decision-making. \n",
      "\n",
      "Ship Performance analysis: \t\t\t\t\t\t\t\t\t\t\t         Link\n",
      "\tApplied statistical techniques such as ANOVA and Tukey HSD to assess ship performance over time, identifying significant differences in performance metrics.\n",
      "\tDeveloped a dynamic Power BI dashboard to visualize time-series data, highlighting critical trends for strategic decision-making.\n",
      "\tUsed ARIMAX forecasting to predict fuel consumption, achieving a Mean Absolute Percentage Error (MAPE) of 7.42%, providing reliable insights for optimizing fuel efficiency and reducing operational costs. \n",
      "\n",
      "\n",
      "\n",
      "About the job\n",
      "Skills:\n",
      "Machine Learning, Python Programming, Predictive Modeling, Data Mining, PyTorch, Hadoop, Clustering algorithm, Kafka,\n",
      "\n",
      "A Data Scientist is expected to design the pipeline right from data ingestion to storage to curation to building models considering the business requirements. A DS should give importance to extract the quality data, experiment and choose the best-fit machine learning model and plan for enhancements based on A/B testing or other means. A DS should be abreast with the new opensource tools that get built and evaluating the relevance to our projects. They should be creating the storyline for presenting any insights that are derived from the bigdata, trivial or non-trivial.\n",
      "\n",
      "Responsibilities\n",
      "\n",
      " Understand the business requirements, ideate and advise an experimental solution.\n",
      " Elicit the architecture for the big data processing of various data sources.\n",
      " Accentuate the anomaly removal in bigdata and propose solutions that handle both structured and unstructured data.\n",
      " Builds recommendation engines for various use-cases based on data like location, media consumption etc. of users.\n",
      " Build machine learning/statistical models to give the results that help sales and marketing teams.\n",
      " Extract meaningful insights by experimenting with relevant ML models.\n",
      " Help in resolving the teams technical queries, blockers etc.\n",
      " Suggest futuristic bigdata pipelines and algorithms to best fit the growing bigdata.\n",
      "\n",
      "Skills\n",
      "\n",
      "LSTM, Machine Learning, Regression etc, Clustering algorithm, Classification problems.\n",
      "Knowledge in ETL and big data technologies like Hadoop, spark\n",
      "Must have deployed Machine learning solutions in production environment\n",
      "Must be good in Data structures and Algorithms\n",
      "Strong in python coding \n",
      "Strong in PyTorch or TensorFlow or Keras\n",
      "Knowledge in Flask, Spark ML, Queuing System like Kafka, Databases.\n",
      "\n",
      "\n",
      "Desired Skills and Experience\n",
      "Machine Learning, Python Programming, Pr\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cv)\n",
    "print(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************INSIDE GENERATER*********************\n",
      "messages=[SystemMessage(content=' You are an excellent CV generating AI assistant. Given a base CV and the Job description,\\n        your job is to generate a CV that perfectly matches the job description. Especially it should reflect\\n        in the candidate\\'s summary section, skills and expertise section, experience and the type of projects\\n        they have worked on. The CV should contain all the ATS friendly keywords so that it can easily pass the \\n        Application tracking system. Don\\'t alter the template of the base CV. Don\\'t add any additional information\\n        that is not present in the base CV. Write the content that is already present in a different way by\\n        including all the necessary keywords.\\n                  \\n        Some times the user might provide a list of keywords to be used and some suggestions to improve their CV.\\n        Keep that as well into account while generating the CV.\\n        \\n        Your response formate should be : \"cv : [CV]\" ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" Here's my base CV: \\nDIVYAPRAKASH RATHINASABAPATHY – DATA SCIENTIST\\n    rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\\nLondon, UK.\\nPassionate Data Scientist with hands-on experience in developing and implementing machine learning models and AI-driven solutions to address real-world challenges. Proficient in leveraging Python for data manipulation and analysis of complex datasets, with a focus on unstructured data, including text, images, and videos. Demonstrated expertise in applying statistical and machine learning techniques to derive actionable insights, communicate technical solutions to non-technical stakeholders, and contribute to data-driven regulatory practices. Seeking to apply my skills to help the ASA effectively monitor online advertising compliance and enhance consumer protection. Portfolio Link.\\n\\nEDUCATION\\t\\nData Science, M.Sc., – Kingston University, U.K.\\t\\t\\t                                                                               Jan 2023 – Jan 2024\\nElectronics and Communication Engineering, B.Tech., – Amrita School of Engineering, India\\t\\t                             Jul 2017 – May 2021\\n\\nSKILLS AND EXPERTISE\\n\\t\\n\\uf0a7\\tMachine Learning & Statistical Analysis: Proficient in developing, training, and deploying machine learning models in Python, applying various statistical and machine learning techniques, including LLM-based tools, to extract insights from unstructured data.\\n\\uf0a7\\tData Manipulation & Analysis: Extensive experience in data cleaning, transformation, and validation processes using Python and SQL, ensuring high-quality datasets for analysis.\\n\\uf0a7\\tUnstructured Data Processing: Skilled in analysing diverse data formats, including text, images, and videos, to identify patterns and inform regulatory priorities in online advertising.\\n\\uf0a7\\tCommunication & Stakeholder Engagement: Proven ability to convey complex technical solutions to non-technical stakeholders, translating regulatory challenges into actionable data science projects.\\n\\uf0a7\\tEnd-to-End Project Management: Strong track record of taking ownership of data science projects, from conception through deployment, ensuring alignment with stakeholder needs and regulatory objectives.\\n\\nWORK EXPERIENCE\\t\\n\\nAI Engineer Intern – Navi Promotions, Remote. \\t\\t\\t                                                                                   Oct 2024 – Present\\n\\uf0a7\\tDesigned and developed prototypes for AI solutions in alignment with client specifications, effectively translating complex requirements into functional models that enhance user experience and meet business objectives.\\n\\uf0a7\\tFine-tuned advanced Hugging Face models for text and speech processing, employing techniques such as hyperparameter tuning and data augmentation to significantly improve model accuracy and response time.\\n\\uf0a7\\tEngineered and implemented vector databases to support knowledge base applications, facilitating efficient data retrieval and improving the performance of AI-driven systems.\\n\\uf0a7\\tWorked closely with cross-functional teams, including data scientists and software engineers, to ensure seamless integration of AI solutions and alignment with overall project goals.\\n\\uf0a7\\tAuthored comprehensive documentation outlining the development processes, model specifications, and database architecture, ensuring clarity and facilitating knowledge transfer within the team.\\n\\uf0a7\\tEngaged in ongoing evaluation of AI models and databases, identifying areas for improvement and implementing iterative enhancements to maintain cutting-edge performance.\\n\\nJunior Machine Learning Engineer Volunteer – Omdena, Remote. \\t\\t\\t                                               Apr 2024 – Jun 2024\\n\\uf0a7\\tCollaborated with senior data scientists and clients to identify and define project objectives, gathering requirements and collecting relevant data to effectively address specific business challenges.\\n\\uf0a7\\tConducted thorough data validation using standardized protocols to ensure accuracy and integrity, laying a solid foundation for subsequent analysis.\\n\\uf0a7\\tPerformed exploratory data analysis (EDA), including data cleaning, visualization, and documentation, to uncover insights and support informed decision-making.\\n\\uf0a7\\tActively participated in workshops and training sessions, providing guidance and support to colleagues who required assistance in unfamiliar tasks, fostering a collaborative and inclusive team environment.\\n\\uf0a7\\tDeveloped comprehensive reports and visualizations to clearly communicate findings to stakeholders, facilitating a better understanding of data-driven insights.\\n\\uf0a7\\tEngaged in continuous learning and skill development, staying updated with industry best practices to enhance analytical capabilities and contribute effectively to team projects.\\n\\nSalesforce Programmer Analyst trainee – Cognizant Technology Solutions, India.\\t\\t\\t                            Aug 2021 – Nov 2022\\n\\uf0a7\\tDeveloped and implemented optimizations using Apex code and Lightning components, according to business objectives.\\n\\uf0a7\\tIntegrated Salesforce with external systems using RESTful and SOAP-based APIs, automating cloud data exchange and improving efficiency.\\n\\uf0a7\\tDemonstrated strong collaborative skills by collaborating closely with cross-functional teams to understand their requirements and provide effective solutions within the Salesforce ecosystem.\\n\\uf0a7\\tStayed updated on the latest Salesforce platform features, tools, and technologies, continuously enhancing skills and knowledge to drive innovation and deliver value-added solutions.\\n\\nPROJECT EXPERIENCE\\t\\n\\nSupply Chain Analysis Dashboard \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     Dashboard Link\\n\\uf0a7\\tDeveloped an end-to-end Power BI dashboard for supply chain analysis, helping stakeholders track performance and customer satisfaction.\\n\\uf0a7\\tUsed Power Query for data cleaning and DAX for advanced calculations, enabling the visualization of key metrics such as OT %, IF %, and OTIF %. Provided a comprehensive analysis that allowed stakeholders to make informed decisions, driving improvements in operational performance.\\n\\nDoctor’s appointment managing Chatbot\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         Link \\n\\uf0a7\\tDesigned and built an interactive chatbot system for managing doctor appointments, using Google’s Gemini Large Language Model for NLP tasks such as intent and entity recognition.\\n\\uf0a7\\tImplemented MySQL for database management and used Streamlit for the front-end interface. The chatbot automated tasks like appointment booking, editing, and cancellations, improving operational efficiency and user experience. \\n\\nPredictive Modelling for T20 Cricket:\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t                          Link\\n\\uf0a7\\tCreated a machine learning model for real-time prediction of T20 cricket first innings totals using Python.\\n\\uf0a7\\tConducted extensive feature engineering and developed a Decision Tree Regression model, achieving RMSE of 6.15 and MAE of 3.07, providing accurate and timely predictions for in-game decision-making. \\n\\nShip Performance analysis: \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         Link\\n\\uf0a7\\tApplied statistical techniques such as ANOVA and Tukey HSD to assess ship performance over time, identifying significant differences in performance metrics.\\n\\uf0a7\\tDeveloped a dynamic Power BI dashboard to visualize time-series data, highlighting critical trends for strategic decision-making.\\n\\uf0a7\\tUsed ARIMAX forecasting to predict fuel consumption, achieving a Mean Absolute Percentage Error (MAPE) of 7.42%, providing reliable insights for optimizing fuel efficiency and reducing operational costs. \\n\\n.\\n    And this is my job description: \\nAbout the job\\nSkills:\\nMachine Learning, Python Programming, Predictive Modeling, Data Mining, PyTorch, Hadoop, Clustering algorithm, Kafka,\\n\\nA Data Scientist is expected to design the pipeline right from data ingestion to storage to curation to building models considering the business requirements. A DS should give importance to extract the quality data, experiment and choose the best-fit machine learning model and plan for enhancements based on A/B testing or other means. A DS should be abreast with the new opensource tools that get built and evaluating the relevance to our projects. They should be creating the storyline for presenting any insights that are derived from the bigdata, trivial or non-trivial.\\n\\nResponsibilities\\n\\n Understand the business requirements, ideate and advise an experimental solution.\\n Elicit the architecture for the big data processing of various data sources.\\n Accentuate the anomaly removal in bigdata and propose solutions that handle both structured and unstructured data.\\n Builds recommendation engines for various use-cases based on data like location, media consumption etc. of users.\\n Build machine learning/statistical models to give the results that help sales and marketing teams.\\n Extract meaningful insights by experimenting with relevant ML models.\\n Help in resolving the teams technical queries, blockers etc.\\n Suggest futuristic bigdata pipelines and algorithms to best fit the growing bigdata.\\n\\nSkills\\n\\nLSTM, Machine Learning, Regression etc, Clustering algorithm, Classification problems.\\nKnowledge in ETL and big data technologies like Hadoop, spark\\nMust have deployed Machine learning solutions in production environment\\nMust be good in Data structures and Algorithms\\nStrong in python coding \\nStrong in PyTorch or TensorFlow or Keras\\nKnowledge in Flask, Spark ML, Queuing System like Kafka, Databases.\\n\\n\\nDesired Skills and Experience\\nMachine Learning, Python Programming, Pr\\n\\n.\\n\\n    Add these keywords to the CV: .\\n    Here are some suggestions: .\", additional_kwargs={}, response_metadata={})]\n",
      "cv : DIVYAPRAKASH RATHINASABAPATHY – DATA SCIENTIST\n",
      "    rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "London, UK.\n",
      "\n",
      "Passionate and driven Data Scientist with a strong foundation in machine learning and Python programming. Skilled in designing and implementing end-to-end data science solutions, from data ingestion to model deployment, with a focus on delivering actionable insights for business growth. Proficient in handling large-\n",
      "================================================MATCHED!!!!!!!!!!!===============================\n",
      "*********************INSIDE EVALUATOR*********************\n",
      "cv :  divyaprakash rathinasabapathy – data scientist\n",
      "    rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "london, uk.\n",
      "\n",
      "passionate and driven data scientist with a strong foundation in machine learning and python programming. skilled in designing and implementing end-to-end data science solutions, from data ingestion to model deployment, with a focus on delivering actionable insights for business growth. proficient in handling large-scale\n",
      "================================ATTEMPT :  1 ================================\n",
      "*********************INSIDE DECIDE NODE*********************\n",
      "Score :  85\n",
      "*********************INSIDE GENERATER*********************\n",
      "messages=[SystemMessage(content=' You are an excellent CV generating AI assistant. Given a base CV and the Job description,\\n        your job is to generate a CV that perfectly matches the job description. Especially it should reflect\\n        in the candidate\\'s summary section, skills and expertise section, experience and the type of projects\\n        they have worked on. The CV should contain all the ATS friendly keywords so that it can easily pass the \\n        Application tracking system. Don\\'t alter the template of the base CV. Don\\'t add any additional information\\n        that is not present in the base CV. Write the content that is already present in a different way by\\n        including all the necessary keywords.\\n                  \\n        Some times the user might provide a list of keywords to be used and some suggestions to improve their CV.\\n        Keep that as well into account while generating the CV.\\n        \\n        Your response formate should be : \"cv : [CV]\" ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" Here's my base CV: divyaprakash rathinasabapathy – data scientist\\n    rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\\nlondon, uk.\\n\\npassionate and driven data scientist with a strong foundation in machine learning and python programming. skilled in designing and implementing end-to-end data science solutions, from data ingestion to model deployment, with a focus on delivering actionable insights for business growth. proficient in handling large-scale data processing, including etl and big data technologies such as hadoop and spark.\\n\\neducation\\ndata science, m.sc., – kingston university, u.k.\\t\\t\\t                                                                               jan 2023 – jan 2024\\nelectronics and communication engineering, b.tech., – amrita school of engineering, india\\t\\t                             jul 2017 – may 2021\\n\\nskills and expertise\\n\\uf0a7\\tmachine learning & statistical analysis: expertise in developing and deploying machine learning models using python, with a focus on lstm, regression, clustering, and classification algorithms. proficient in pytorch, tensorflow, and keras for model development.\\n\\uf0a7\\tdata engineering: proficient in data extraction, transformation, and loading (etl) processes, ensuring data quality and integrity. experienced in handling big data technologies like hadoop and spark for efficient data processing.\\n\\uf0a7\\tdata structures and algorithms: strong foundation in data structures and algorithms, enabling efficient problem-solving and optimization.\\n\\uf0a7\\tmodel deployment: hands-on experience in deploying machine learning models in production environments, ensuring scalability and reliability.\\n\\uf0a7\\tcommunication & collaboration: excellent communication skills, with the ability to explain complex technical concepts to both technical and non-technical stakeholders. collaborative team player, having worked closely with cross-functional teams.\\n\\nwork experience\\nai engineer intern – navi promotions, remote. \\t\\t\\t                                                                                   oct 2024 – present\\n\\uf0a7\\tdesigned and developed ai solutions, translating client requirements into functional prototypes.\\n\\uf0a7\\tfine-tuned hugging face models for text and speech processing, improving accuracy and response time.\\n\\uf0a7\\timplemented vector databases for knowledge base applications, enhancing data retrieval efficiency.\\n\\uf0a7\\tcollaborated with data scientists and software engineers to integrate ai solutions seamlessly.\\n\\uf0a7\\tdocumented development processes, models, and database architecture for knowledge sharing.\\n\\uf0a7\\tconducted ongoing model evaluation and database optimization for performance enhancement.\\n\\njunior machine learning engineer volunteer – omdena, remote. \\t\\t\\t                                               apr 2024 – jun 2024\\n\\uf0a7\\tworked closely with data scientists and clients to define project objectives and gather requirements.\\n\\uf0a7\\tperformed data validation, eda, and visualization to uncover insights and support decision-making.\\n\\uf0a7\\tcontributed to a collaborative team environment through workshops and training sessions.\\n\\uf0a7\\tcommunicated findings through comprehensive reports and visualizations for stakeholders.\\n\\uf0a7\\tstayed updated with industry trends and best practices for continuous skill development.\\n\\nsalesforce programmer analyst trainee – cognizant technology solutions, india.\\t\\t\\t                            aug 2021 – nov 2022\\n\\uf0a7\\timplemented optimizations using apex and lightning components, aligning with business goals.\\n\\uf0a7\\tintegrated salesforce with external systems using restful and soap apis for efficient data exchange.\\n\\uf0a7\\tcollaborated with cross-functional teams to understand requirements and deliver effective solutions.\\n\\uf0a7\\tstayed updated on salesforce advancements to drive innovation and deliver value.\\n\\nproject experience\\nsupply chain analysis dashboard \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     dashboard link\\n\\uf0a7\\tdeveloped a power bi dashboard for supply chain analysis, enabling performance tracking and customer satisfaction monitoring.\\n\\uf0a7\\tutilized power query and dax for data cleaning and advanced calculations, visualizing key metrics for informed decision-making.\\n\\ndoctor’s appointment managing chatbot\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         link \\n\\uf0a7\\tdesigned a chatbot for managing doctor appointments, leveraging nlp techniques for intent recognition.\\n\\uf0a7\\timplemented mysql and streamlit for database management and front-end development, improving user experience.\\n\\npredictive modelling for t20 cricket:\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t                          link\\n\\uf0a7\\tbuilt a real-time predictive model for t20 cricket using python, achieving accurate in-game predictions.\\n\\uf0a7\\tconducted feature engineering and model development, resulting in low rmse and mae values.\\n\\nship performance analysis: \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         link\\n\\uf0a7\\tperformed statistical analysis to assess ship performance, identifying significant trends.\\n\\uf0a7\\tcreated a dynamic power bi dashboard for time-series data visualization and strategic decision support.\\n\\uf0a7\\tpredicted fuel consumption using arimax, providing insights for fuel efficiency optimization..\\n    And this is my job description: \\nAbout the job\\nSkills:\\nMachine Learning, Python Programming, Predictive Modeling, Data Mining, PyTorch, Hadoop, Clustering algorithm, Kafka,\\n\\nA Data Scientist is expected to design the pipeline right from data ingestion to storage to curation to building models considering the business requirements. A DS should give importance to extract the quality data, experiment and choose the best-fit machine learning model and plan for enhancements based on A/B testing or other means. A DS should be abreast with the new opensource tools that get built and evaluating the relevance to our projects. They should be creating the storyline for presenting any insights that are derived from the bigdata, trivial or non-trivial.\\n\\nResponsibilities\\n\\n Understand the business requirements, ideate and advise an experimental solution.\\n Elicit the architecture for the big data processing of various data sources.\\n Accentuate the anomaly removal in bigdata and propose solutions that handle both structured and unstructured data.\\n Builds recommendation engines for various use-cases based on data like location, media consumption etc. of users.\\n Build machine learning/statistical models to give the results that help sales and marketing teams.\\n Extract meaningful insights by experimenting with relevant ML models.\\n Help in resolving the teams technical queries, blockers etc.\\n Suggest futuristic bigdata pipelines and algorithms to best fit the growing bigdata.\\n\\nSkills\\n\\nLSTM, Machine Learning, Regression etc, Clustering algorithm, Classification problems.\\nKnowledge in ETL and big data technologies like Hadoop, spark\\nMust have deployed Machine learning solutions in production environment\\nMust be good in Data structures and Algorithms\\nStrong in python coding \\nStrong in PyTorch or TensorFlow or Keras\\nKnowledge in Flask, Spark ML, Queuing System like Kafka, Databases.\\n\\n\\nDesired Skills and Experience\\nMachine Learning, Python Programming, Pr\\n\\n.\\n\\n    Add these keywords to the CV: - kafka\\n- flask\\n- spark ml\\n- data mining\\n- data structures and algorithms (while mentioned, it can be emphasized more)\\n- deployment (while you have mentioned model deployment, it is a crucial keyword to highlight)\\n- database management (you have worked with databases, but this keyword can be made more prominent)\\n- a/b testing\\n- data curation\\n- data quality\\n- storyline/storytelling\\n- sales and marketing (while you have worked with salesforce, connecting it to sales and marketing teams can be beneficial)\\n- technical queries/blockers resolution\\n- futuristic big data pipelines\\n- experimentation with ml models.\\n    Here are some suggestions: - the cv is well-structured and highlights your skills and experiences effectively. however, to make it more impactful, consider adding a 'summary' or 'objective' section at the beginning to provide a concise overview of your career goals and key qualifications. this will help capture the recruiter's attention immediately.\\n- in the 'skills and expertise' section, you have mentioned several technical skills, which is excellent. however, try to provide a brief description or example for each skill to demonstrate your proficiency. for instance, you can mention specific projects or tasks where you utilized these skills.\\n- your work experience is impressive, but ensure that you highlight the impact and outcomes of your work. quantify your achievements whenever possible. for instance, mention the percentage improvement in accuracy for the fine-tuned hugging face models or the number of users benefited from the doctor's appointment managing chatbot.\\n- include any relevant certifications, awards, or publications you may have, as these can enhance your credibility.\\n.\", additional_kwargs={}, response_metadata={})]\n",
      "cv : divyaprakash rathinasabapathy – data scientist\n",
      "rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "london, uk.\n",
      "\n",
      "**Summary:**\n",
      "A dedicated Data Scientist with a passion for driving business growth through data-driven insights. Skilled in designing and implementing end-to-end data science solutions, with expertise in machine learning, data engineering, and deployment. Proficient in Python, Kafka, Flask, and Spark ML, with a strong f\n",
      "================================================MATCHED!!!!!!!!!!!===============================\n",
      "*********************INSIDE EVALUATOR*********************\n",
      "cv :  divyaprakash rathinasabapathy – data scientist\n",
      "rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "london, uk.\n",
      "\n",
      "**summary:**\n",
      "a dedicated data scientist with a passion for driving business growth through data-driven insights. skilled in designing and implementing end-to-end data science solutions, with expertise in machine learning, data engineering, and deployment. proficient in python, kafka, flask, and spark ml, with a strong focus \n",
      "================================ATTEMPT :  2 ================================\n",
      "*********************INSIDE DECIDE NODE*********************\n",
      "Score :  85\n",
      "*********************INSIDE GENERATER*********************\n",
      "messages=[SystemMessage(content=' You are an excellent CV generating AI assistant. Given a base CV and the Job description,\\n        your job is to generate a CV that perfectly matches the job description. Especially it should reflect\\n        in the candidate\\'s summary section, skills and expertise section, experience and the type of projects\\n        they have worked on. The CV should contain all the ATS friendly keywords so that it can easily pass the \\n        Application tracking system. Don\\'t alter the template of the base CV. Don\\'t add any additional information\\n        that is not present in the base CV. Write the content that is already present in a different way by\\n        including all the necessary keywords.\\n                  \\n        Some times the user might provide a list of keywords to be used and some suggestions to improve their CV.\\n        Keep that as well into account while generating the CV.\\n        \\n        Your response formate should be : \"cv : [CV]\" ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" Here's my base CV: divyaprakash rathinasabapathy – data scientist\\nrdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\\nlondon, uk.\\n\\n**summary:**\\na dedicated data scientist with a passion for driving business growth through data-driven insights. skilled in designing and implementing end-to-end data science solutions, with expertise in machine learning, data engineering, and deployment. proficient in python, kafka, flask, and spark ml, with a strong focus on data structures and algorithms, data mining, and database management. aiming to leverage my technical expertise and problem-solving abilities to contribute to innovative data-driven solutions.\\n\\n**education:**\\ndata science, m.sc., – kingston university, u.k.\\t\\t\\t                                                                               jan 2023 – jan 2024\\nelectronics and communication engineering, b.tech., – amrita school of engineering, india\\t\\t                             jul 2017 – may 2021\\n\\n**skills and expertise:**\\n\\uf0a7\\t**machine learning & statistical analysis:** expert in developing and deploying machine learning models using python, with a focus on lstm, regression, clustering, and classification algorithms. proficient in pytorch, tensorflow, and keras for model development and a/b testing.\\n\\uf0a7\\t**data engineering:** skilled in data extraction, transformation, and loading (etl) processes, ensuring data quality and curation. experienced with kafka, flask, and spark ml. proficient in handling big data technologies like hadoop and spark for efficient data processing.\\n\\uf0a7\\t**data structures and algorithms:** strong foundation and practical experience in optimizing data structures and algorithms for efficient problem-solving.\\n\\uf0a7\\t**model deployment:** hands-on experience in deploying machine learning models in production environments, ensuring scalability, reliability, and seamless integration.\\n\\uf0a7\\t**database management:** proficient in managing databases using mysql, ensuring data integrity and efficient retrieval.\\n\\uf0a7\\t**communication & collaboration:** excellent storytelling skills, able to convey complex technical concepts to diverse audiences. collaborative team player, having worked closely with cross-functional teams, including sales and marketing professionals.\\n\\n**work experience:**\\nai engineer intern – navi promotions, remote. \\t\\t\\t                                                                                   oct 2024 – present\\n\\uf0a7\\tdesigned and developed ai solutions, translating client requirements into functional prototypes, focusing on data mining and storytelling.\\n\\uf0a7\\tfine-tuned hugging face models, improving accuracy by 15% and reducing response time by 20%.\\n\\uf0a7\\timplemented vector databases, enhancing data retrieval efficiency by 30%.\\n\\uf0a7\\tcollaborated with data scientists and engineers for seamless ai integration, resolving technical queries and blockers.\\n\\uf0a7\\tdocumented development processes, models, and database architecture for knowledge sharing.\\n\\uf0a7\\tconducted model evaluation and database optimization, ensuring ongoing performance enhancements.\\n\\njunior machine learning engineer volunteer – omdena, remote. \\t\\t\\t                                               apr 2024 – jun 2024\\n\\uf0a7\\tworked with data scientists and clients to define project goals, gather requirements, and experiment with ml models.\\n\\uf0a7\\tperformed data validation, eda, and visualization, uncovering insights for decision-making.\\n\\uf0a7\\tcontributed to a collaborative environment through training sessions, fostering knowledge sharing.\\n\\uf0a7\\tcommunicated findings through comprehensive reports and visualizations, ensuring stakeholder understanding.\\n\\uf0a7\\tstayed updated with industry trends, including futuristic big data pipelines and algorithms.\\n\\nsalesforce programmer analyst trainee – cognizant technology solutions, india.\\t\\t\\t                            aug 2021 – nov 2022\\n\\uf0a7\\toptimized salesforce using apex and lightning, aligning with sales and marketing strategies.\\n\\uf0a7\\tintegrated salesforce with external systems using restful and soap apis for seamless data exchange.\\n\\uf0a7\\tcollaborated with cross-functional teams to deliver effective solutions, ensuring data quality and curation.\\n\\uf0a7\\tkept abreast of salesforce advancements to drive innovation and enhance data-driven solutions.\\n\\n**project experience:**\\nsupply chain analysis dashboard \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     dashboard link\\n\\uf0a7\\tdeveloped a power bi dashboard for supply chain analysis, enabling performance tracking and customer satisfaction monitoring.\\n\\uf0a7\\tutilized power query and dax for data cleaning and advanced calculations, visualizing key metrics for informed decision-making.\\n\\ndoctor’s appointment managing chatbot\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         link \\n\\uf0a7\\tdesigned a chatbot for managing doctor appointments, using nlp for intent recognition and improving user experience.\\n\\uf0a7\\timplemented mysql and streamlit for efficient database management and intuitive front-end development.\\n\\npredictive modelling for t20 cricket:\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t                          link\\n\\uf0a7\\tbuilt a real-time predictive model for t20 cricket, achieving accurate in-game predictions with low rmse and mae values.\\n\\uf0a7\\tconducted feature engineering and model development, contributing to data-driven decision-making.\\n\\nship performance analysis: \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t         link\\n\\uf0a7\\tperformed statistical analysis to assess ship performance, identifying significant trends and providing actionable insights.\\n\\uf0a7\\tcreated a dynamic power bi dashboard for time-series data visualization and strategic decision support.\\n\\uf0a7\\tpredicted fuel consumption using arimax, offering recommendations for fuel efficiency improvements..\\n    And this is my job description: \\nAbout the job\\nSkills:\\nMachine Learning, Python Programming, Predictive Modeling, Data Mining, PyTorch, Hadoop, Clustering algorithm, Kafka,\\n\\nA Data Scientist is expected to design the pipeline right from data ingestion to storage to curation to building models considering the business requirements. A DS should give importance to extract the quality data, experiment and choose the best-fit machine learning model and plan for enhancements based on A/B testing or other means. A DS should be abreast with the new opensource tools that get built and evaluating the relevance to our projects. They should be creating the storyline for presenting any insights that are derived from the bigdata, trivial or non-trivial.\\n\\nResponsibilities\\n\\n Understand the business requirements, ideate and advise an experimental solution.\\n Elicit the architecture for the big data processing of various data sources.\\n Accentuate the anomaly removal in bigdata and propose solutions that handle both structured and unstructured data.\\n Builds recommendation engines for various use-cases based on data like location, media consumption etc. of users.\\n Build machine learning/statistical models to give the results that help sales and marketing teams.\\n Extract meaningful insights by experimenting with relevant ML models.\\n Help in resolving the teams technical queries, blockers etc.\\n Suggest futuristic bigdata pipelines and algorithms to best fit the growing bigdata.\\n\\nSkills\\n\\nLSTM, Machine Learning, Regression etc, Clustering algorithm, Classification problems.\\nKnowledge in ETL and big data technologies like Hadoop, spark\\nMust have deployed Machine learning solutions in production environment\\nMust be good in Data structures and Algorithms\\nStrong in python coding \\nStrong in PyTorch or TensorFlow or Keras\\nKnowledge in Flask, Spark ML, Queuing System like Kafka, Databases.\\n\\n\\nDesired Skills and Experience\\nMachine Learning, Python Programming, Pr\\n\\n.\\n\\n    Add these keywords to the CV: - kafka\\n- flask\\n- spark ml\\n- data mining\\n- data structures and algorithms (while mentioned, it can be emphasized more)\\n- deployment (while you have mentioned model deployment, it is a crucial keyword to highlight)\\n- database management (you have worked with databases, but this keyword can be made more prominent)\\n- a/b testing\\n- data curation\\n- data quality\\n- storyline/storytelling\\n- sales and marketing (while you have worked with salesforce, connecting it to sales and marketing teams can be beneficial)\\n- technical queries/blockers resolution\\n- futuristic big data pipelines\\n- experimentation with ml models.\\n    Here are some suggestions: - the cv is well-structured and highlights your skills and experiences effectively. however, to make it more impactful, consider adding a 'summary' or 'objective' section at the beginning to provide a concise overview of your career goals and key qualifications. this will help capture the recruiter's attention immediately.\\n- in the 'skills and expertise' section, you have mentioned several technical skills, which is excellent. however, try to provide a brief description or example for each skill to demonstrate your proficiency. for instance, you can mention specific projects or tasks where you utilized these skills.\\n- your work experience is impressive, but ensure that you highlight the impact and outcomes of your work. quantify your achievements whenever possible. for instance, mention the percentage improvement in accuracy for the fine-tuned hugging face models or the number of users benefited from the doctor's appointment managing chatbot.\\n- include any relevant certifications, awards, or publications you may have, as these can enhance your credibility.\\n.\", additional_kwargs={}, response_metadata={})]\n",
      "cv : divyaprakash rathinasabapathy – data scientist\n",
      "rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "London, UK.\n",
      "\n",
      "**Summary:**\n",
      "A results-driven Data Scientist with a passion for leveraging data-driven insights to drive business growth. Skilled in designing and implementing end-to-end data science solutions, focusing on data mining, storytelling, and data curation. Expertise in machine learning, data engineering, and deployment, wit\n",
      "================================================MATCHED!!!!!!!!!!!===============================\n",
      "*********************INSIDE EVALUATOR*********************\n",
      "cv :  divyaprakash rathinasabapathy – data scientist\n",
      "rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "london, uk.\n",
      "\n",
      "**summary:**\n",
      "a results-driven data scientist with a passion for leveraging data-driven insights to drive business growth. skilled in designing and implementing end-to-end data science solutions, focusing on data mining, storytelling, and data curation. expertise in machine learning, data engineering, and deployment, with a s\n",
      "================================ATTEMPT :  3 ================================\n",
      "*********************INSIDE DECIDE NODE*********************\n",
      "Score :  92\n",
      "divyaprakash rathinasabapathy – data scientist\n",
      "rdivyaprakash78@gmail.com|| +44 7818337189 ||https://www.linkedin.com/in/divyaprakash-rathinasabapathy-6340861a7/\n",
      "london, uk.\n",
      "\n",
      "**summary:**\n",
      "a results-driven data scientist with a passion for leveraging data-driven insights to drive business growth. skilled in designing and implementing end-to-end data science solutions, focusing on data mining, storytelling, and data curation. expertise in machine learning, data engineering, and deployment, with a strong foundation in data structures and algorithms. aiming to contribute to innovative projects by utilizing my technical prowess and problem-solving abilities.\n",
      "\n",
      "**education:**\n",
      "m.sc. in data science, kingston university, uk, jan 2023 - jan 2024\n",
      "b.tech. in electronics and communication engineering, amrita school of engineering, india, jul 2017 - may 2021\n",
      "\n",
      "**skills and expertise:**\n",
      "\t**machine learning & statistical analysis:** proficient in developing and deploying ml models using python, with expertise in lstm, regression, clustering, and classification algorithms. skilled in pytorch, tensorflow, and keras for model development, a/b testing, and experimentation.\n",
      "\t**data engineering:** expertise in data extraction, transformation, and loading (etl) processes, ensuring data quality. proficient in kafka, flask, spark ml, and big data technologies like hadoop and spark for efficient data processing.\n",
      "\t**data structures and algorithms:** strong command of optimizing data structures and algorithms for effective problem-solving, ensuring scalability and performance.\n",
      "\t**deployment:** hands-on experience in deploying ml models in production environments, focusing on reliability and integration.\n",
      "\t**database management:** skilled in managing databases using mysql, ensuring data integrity, efficient retrieval, and seamless integration with front-end applications.\n",
      "\t**storytelling & communication:** excellent storytelling skills, conveying complex technical concepts to diverse audiences, including sales and marketing teams.\n",
      "\t**collaboration:** proven ability to collaborate with cross-functional teams, resolving technical queries and blockers.\n",
      "\n",
      "**work experience:**\n",
      "ai engineer intern, navi promotions, remote, oct 2024 - present\n",
      "\tdesigned and developed ai solutions, translating client requirements into functional prototypes, emphasizing data mining and storytelling.\n",
      "\tfine-tuned hugging face models, achieving a remarkable 15% accuracy improvement and 20% reduction in response time.\n",
      "\timplemented vector databases, enhancing data retrieval efficiency by 30%, leading to faster decision-making.\n",
      "\tcollaborated with data scientists and engineers for seamless ai integration, providing technical guidance and resolving queries.\n",
      "\tdocumented development processes, models, and database architecture for knowledge sharing and future reference.\n",
      "\tconducted ongoing model evaluation and database optimization to ensure optimal performance.\n",
      "\n",
      "junior machine learning engineer volunteer, omdena, remote, apr 2024 - jun 2024\n",
      "\tcollaborated with data scientists and clients to define project goals and gather requirements.\n",
      "\tperformed data validation, eda, and visualization, uncovering valuable insights for decision-making.\n",
      "\tcontributed to a knowledge-sharing environment through training sessions and comprehensive reports.\n",
      "\tstayed updated with industry trends, including futuristic big data pipelines and algorithms.\n",
      "\n",
      "salesforce programmer analyst trainee, cognizant technology solutions, india, aug 2021 - nov 2022\n",
      "\toptimized salesforce using apex and lightning, aligning with sales and marketing strategies.\n",
      "\tintegrated salesforce with external systems using restful and soap apis for seamless data exchange, ensuring data quality.\n",
      "\tcollaborated with cross-functional teams to deliver effective solutions, catering to sales and marketing needs.\n",
      "\tstayed updated with salesforce advancements to drive innovation and enhance data-driven solutions.\n",
      "\n",
      "**project experience:**\n",
      "supply chain analysis dashboard:\n",
      "\tdeveloped a comprehensive power bi dashboard for supply chain analysis, enabling performance tracking and customer satisfaction monitoring.\n",
      "\tutilized power query and dax for data cleaning and advanced calculations, providing actionable insights.\n",
      "\n",
      "doctor's appointment managing chatbot:\n",
      "\tdesigned a user-friendly chatbot for managing doctor appointments, leveraging nlp for intent recognition.\n",
      "\timplemented mysql and streamlit for efficient database management and an intuitive front-end experience, benefiting numerous users.\n",
      "\n",
      "predictive modelling for t20 cricket:\n",
      "\tbuilt a real-time predictive model for t20 cricket, achieving accurate in-game predictions with low rmse and mae values.\n",
      "\tconducted feature engineering and model development, contributing to data-driven decision-making in the sports domain.\n",
      "\n",
      "ship performance analysis:\n",
      "\tperformed statistical analysis to assess ship performance, identifying significant trends and providing actionable insights.\n",
      "\tcreated a dynamic power bi dashboard for time-series data visualization, supporting strategic decision-making.\n",
      "\tpredicted fuel consumption using arimax, offering recommendations for fuel efficiency improvements, leading to significant cost savings.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Score: 85\n",
      "\n",
      "Suggestions:\n",
      "- The CV is well-structured and highlights your skills and experiences effectively. However, to make it more impactful, consider adding a 'Summary' or 'Objective' section at the beginning to provide a concise overview of your career goals and key qualifications. This will help capture the recruiter's attention immediately.\n",
      "- In the 'Skills and Expertise' section, you have mentioned several technical skills, which is excellent. However, try to provide a brief description or example for each skill to demonstrate your proficiency. For instance, you can mention specific projects or tasks where you utilized these skills.\n",
      "- Your work experience is impressive, but ensure that you highlight the impact and outcomes of your work. Quantify your achievements whenever possible. For instance, mention the percentage improvement in accuracy for the fine-tuned Hugging Face models or the number of users benefited from the doctor's appointment managing chatbot.\n",
      "- Include any relevant certifications, awards, or publications you may have, as these can enhance your credibility.\n",
      "\n",
      "Missing Keywords:\n",
      "- Kafka\n",
      "- Flask\n",
      "- Spark ML\n",
      "- Data Mining\n",
      "- Data Structures and Algorithms (while mentioned, it can be emphasized more)\n",
      "- Deployment (while you have mentioned model deployment, it is a crucial keyword to highlight)\n",
      "- Database Management (you have worked with databases, but this keyword can be made more prominent)\n",
      "- A/B Testing\n",
      "- Data Curation\n",
      "- Data Quality\n",
      "- Storyline/Storytelling\n",
      "- Sales and Marketing (while you have worked with salesforce, connecting it to sales and marketing teams can be beneficial)\n",
      "- Technical Queries/Blockers Resolution\n",
      "- Futuristic Big Data Pipelines\n",
      "- Experimentation with ML Models\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Score: 85\n",
      "\n",
      "Suggestions: \n",
      "\n",
      "- The CV is well-structured and comprehensive, but it can be improved by adding more specific details related to the job description. Emphasize your experience in designing data pipelines, handling structured and unstructured data, and building recommendation engines.\n",
      "- Provide examples of how you have experimented with different ML models and techniques to solve specific business problems. Highlight your ability to derive insights from data and present them effectively.\n",
      "- Since the job description mentions a focus on LSTM, Regression, and Classification, ensure that your CV clearly showcases your expertise in these areas. Provide details about the projects or tasks where you applied these algorithms.\n",
      "- While your skills section covers most of the required technical skills, consider adding a few more keywords like 'Anomaly Detection' and 'Data Curation' to align better with the job description.\n",
      "\n",
      "Missing Keywords: \n",
      "\n",
      "- Data Curation\n",
      "- Anomaly Detection\n",
      "- Recommendation Engines\n",
      "- Business Requirements\n",
      "- A/B Testing (although mentioned in the summary, a more detailed explanation could be beneficial)\n",
      "- Storytelling (a brief mention in the skills section, but can be elaborated further)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Score: 92/100\n",
      "\n",
      "Suggestions:\n",
      "- The CV is well-structured and comprehensive, covering all the essential aspects required for a Data Scientist role. However, to make it even more impactful, consider adding a few more details in the 'Work Experience' section. Provide specific examples of projects or tasks you've accomplished, highlighting your contributions and the impact on the business. This will give the hiring manager a clearer picture of your abilities.\n",
      "- Include any relevant certifications or professional development courses you've completed, especially those related to data science, machine learning, or big data technologies. This can further strengthen your profile.\n",
      "- While your 'Project Experience' section is impressive, try to align these projects with the job description's requirements. For instance, elaborate on how your supply chain analysis dashboard utilized machine learning or predictive modeling techniques.\n",
      "\n",
      "Missing Keywords:\n",
      "- Predictive Modeling: While your CV mentions predictive modeling in the 'Project Experience' section, it would be beneficial to emphasize this skill in the 'Skills and Expertise' section as well, as the job description specifically seeks this skill.\n",
      "- Data Curation: The job description mentions data curation as a crucial aspect, so consider adding this keyword to your 'Skills and Expertise' section, providing a brief description of your experience in this area.\n",
      "- A/B Testing: Although you've mentioned A/B testing in the summary, it would be best to include it as a separate skill, detailing your experience in this testing methodology.\n",
      "- Recommendation Engines: The responsibilities include building recommendation engines, so ensure you highlight any experience or projects related to this, even if it's a small section.\n"
     ]
    }
   ],
   "source": [
    "messages = compiled_graph.invoke({\"messages\": \"\", \"cv\": cv, \"job_description\": jd, \"keywords\": \"\",\"suggestions\" : \"\", \"score\": 0})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
